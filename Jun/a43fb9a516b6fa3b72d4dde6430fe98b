WhatsApp has launched its first major privacy-focused advertising campaign in the UK. It follows a customer backlash against changes to its terms and conditions, announced earlier this year. The platform also said it is standing firm against pressure from governments, including the UK, to compromise on the way that it encrypts messages. Authorities should “demand more security” rather than less, WhatsApp boss Will Cathcart told the BBC. “The first step of keeping people safe is, you have to have strong security, and we think governments shouldn’t be out there trying to encourage tech companies to offer weak security,” he said. “They should be out there trying to encourage or even mandate that companies offer the strongest security possible.” The marketing campaign is set to run internationally, beginning in the UK and Germany on Monday. WhatsApp uses end-to-end encryption, which means messages can only be read on the device which sends one and the device which receives it. WhatsApp itself – and by default its parent company Facebook – cannot view or intercept them, and neither can law enforcement. Home Secretary Priti Patel has described the use of end-to-end encryption as “not acceptable  in the fight against the sharing of illegal content. In a speech in April said she wanted to see it used “in a way in which is also consistent with public protection and child safety” but did not elaborate on how this might work. Facebook says it intends to roll out encryption more broadly across its other services. WhatsApp is already blocked in mainland China, and it is suing the Indian government over new digital rules that will force it to violate its privacy protections. Around 400 million of its two billion global users are in India. Mr Cathcart said he “lives with the reality” that more countries could also choose to block the platform as tech sector regulations tighten around the world. While the firm cannot see the content of messages, it has developed other tools which help it block illegal material and widely-shared misinformation. WhatsApp bans two million accounts every month, and in 2020 the platform reported 300,000 images to the National Centre for Missing Exploited Children, Mr Cathcart said. It does this using a combination of reports from message recipients, and machine-learning using the unencrypted data that WhatsApp can see – such as the volume of messages an account sends and how many groups it joins. Messages that have been forwarded lots of times before are also now flagged, and there are limits on how many people one user can share the same message with. In January, thousands of users threatened to leave WhatsApp, wrongly thinking it was going to start sharing messaging data with Facebook following an announcement about changes to its terms and conditions. Those who did not accept the update would begin to lose functionality, it said. There were false claims that the privacy of personal messages was about to change, and thousands of alarmed people flocked to rival services such as Signal and Telegram. In fact the changes are mainly related to enabling companies to accept payments via WhatsApp. Will Cathcart said the firm took responsibility for the “confusion” the announcement had created. “To reiterate, nothing about the privacy of people’s personal conversations changed in our update,” he said. – bbc.com